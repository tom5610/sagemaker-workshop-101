{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athena SQL Model\n",
    "\n",
    "This example will create an athena table for [Jan 2017 taxi dataset](https://aws.amazon.com/blogs/big-data/build-a-data-lake-foundation-with-aws-glue-and-amazon-s3/).  You can improve performance if you convert into a parquet format.\n",
    "\n",
    "Configure your notebook role with permissions to [query data from athena](https://aws.amazon.com/blogs/machine-learning/run-sql-queries-from-your-sagemaker-notebooks-using-amazon-athena/) and access the s3 staging bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries\n",
    "\n",
    "Install the [Athena library](https://pypi.org/project/PyAthena/) for python and [tqdm](https://tqdm.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install -U pandas\n",
    "!{sys.executable} -m pip install -U PyAthena[Pandas]==1.11.2\n",
    "!{sys.executable} -m pip install -U tqdm\n",
    "!{sys.executable} -m pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyathena[Pandas]==1.11.2 in /opt/conda/lib/python3.7/site-packages (1.11.2)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.16.35)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.19.35)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (0.18.2)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (6.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.0.1)\n",
      "Requirement already satisfied: pyarrow>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (2.0.0)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.19.35)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.4.4->pyathena[Pandas]==1.11.2) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.4.4->pyathena[Pandas]==1.11.2) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.5.52->pyathena[Pandas]==1.11.2) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.5.52->pyathena[Pandas]==1.11.2) (2.8.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.4.4->pyathena[Pandas]==1.11.2) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->pyathena[Pandas]==1.11.2) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.5.52->pyathena[Pandas]==1.11.2) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->pyathena[Pandas]==1.11.2) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->pyathena[Pandas]==1.11.2) (1.18.1)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.16.35)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.19.35)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (0.18.2)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (6.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.5.52->pyathena[Pandas]==1.11.2) (1.14.0)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /opt/conda/lib/python3.7/site-packages (from pyathena[Pandas]==1.11.2) (1.19.35)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.5.52->pyathena[Pandas]==1.11.2) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyathena[Pandas]==1.11.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Kernel\n",
    "\n",
    "Now that you have upgraded SageMaker you need to restart the kernel by clicking menu: `Kernel -> Restart & Clear Output`.\n",
    "\n",
    "Once restarted, run the next cell to check you have version starting with `2.x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker\n",
      "Version: 2.19.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: None\n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: protobuf3-to-dict, importlib-metadata, protobuf, packaging, google-pasta, numpy, attrs, boto3, smdebug-rulesconfig\n",
      "Required-by: \n",
      "\u001b[33mWARNING: Package(s) not found: PyAthena[Pandas]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip show sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Create an anthena database and external table for the imported nyc bit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 staging dir: s3://sagemaker-us-east-1-840276314986/athena\n",
      "athena table: nyc_taxi.taxi_csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Initialize the boto session in us-east-1 region\n",
    "boto_session = boto3.session.Session(region_name='us-east-1')\n",
    "region = boto_session.region_name\n",
    "bucket = sagemaker.session.Session(boto_session).default_bucket()\n",
    "\n",
    "# Get the athena staging dir andtable\n",
    "s3_staging_dir = 's3://{}/athena'.format(bucket)\n",
    "db_name = 'nyc_taxi'\n",
    "table_name = '{}.taxi_csv'.format(db_name)\n",
    "\n",
    "print('s3 staging dir: {}'.format(s3_staging_dir))\n",
    "print('athena table: {}'.format(table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the bucket if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: sagemaker-us-east-1-840276314986\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mb s3://$bucket --region $region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the nyc taxi dataset using [PandasCursor](https://pypi.org/project/PyAthena/#pandascursor) for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "from pyathena.pandas_cursor import PandasCursor\n",
    "import pandas as pd\n",
    "\n",
    "cursor = connect(s3_staging_dir=s3_staging_dir,\n",
    "                 region_name=region,\n",
    "                 cursor_class=PandasCursor).cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: SUCCEEDED, Run time: 0.40s\n"
     ]
    }
   ],
   "source": [
    "sql_ddl_create_table = 'CREATE DATABASE IF NOT EXISTS {};'.format(db_name)\n",
    "\n",
    "cursor.execute(sql_ddl_create_table)\n",
    "print('Status: {}, Run time: {:.2f}s'.format(cursor.state, \n",
    "    cursor.execution_time_in_millis/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: SUCCEEDED, Run time: 0.45s\n"
     ]
    }
   ],
   "source": [
    "sql_create_table = '''\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS `{}` (\n",
    "    `vendorid` bigint, \n",
    "    `lpep_pickup_datetime` string, \n",
    "    `lpep_dropoff_datetime` string, \n",
    "    `store_and_fwd_flag` string, \n",
    "    `ratecodeid` bigint, \n",
    "    `pulocationid` bigint, \n",
    "    `dolocationid` bigint, \n",
    "    `passenger_count` bigint, \n",
    "    `trip_distance` double, \n",
    "    `fare_amount` double, \n",
    "    `extra` double, \n",
    "    `mta_tax` double, \n",
    "    `tip_amount` double, \n",
    "    `tolls_amount` double, \n",
    "    `ehail_fee` string, \n",
    "    `improvement_surcharge` double, \n",
    "    `total_amount` double, \n",
    "    `payment_type` bigint, \n",
    "    `trip_type` bigint)\n",
    "ROW FORMAT DELIMITED \n",
    "    FIELDS TERMINATED BY ',' \n",
    "STORED AS INPUTFORMAT \n",
    "    'org.apache.hadoop.mapred.TextInputFormat' \n",
    "OUTPUTFORMAT \n",
    "    'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "    's3://aws-bigdata-blog/artifacts/glue-data-lake/data/'\n",
    "TBLPROPERTIES (\n",
    "    'columnsOrdered'='true', \n",
    "    'compressionType'='none', \n",
    "    'skip.header.line.count'='1')\n",
    "'''.format(table_name)\n",
    "\n",
    "cursor.execute(sql_create_table)\n",
    "print('Status: {}, Run time: {:.2f}s'.format(cursor.state, \n",
    "    cursor.execution_time_in_millis/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying... \n",
      "SELECT \n",
      "    total_amount, fare_amount, lpep_pickup_datetime, lpep_dropoff_datetime, trip_distance \n",
      "FROM nyc_taxi.taxi_csv WHERE total_amount is not null;\n",
      "\n",
      "Status: SUCCEEDED, Run time: 5.76s, Data scanned: 91.34MB, Records: 1,070,261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.30</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2017-01-22 21:49:27</td>\n",
       "      <td>2017-01-22 22:07:02</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.16</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2017-01-22 21:52:32</td>\n",
       "      <td>2017-01-22 22:15:40</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.56</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2017-01-22 21:07:23</td>\n",
       "      <td>2017-01-22 21:14:19</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.96</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2017-01-22 21:37:01</td>\n",
       "      <td>2017-01-22 21:46:48</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-01-22 21:55:06</td>\n",
       "      <td>2017-01-22 22:03:13</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_amount  fare_amount lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "0         20.30         16.5  2017-01-22 21:49:27   2017-01-22 22:07:02   \n",
       "1         26.16         20.5  2017-01-22 21:52:32   2017-01-22 22:15:40   \n",
       "2         10.56          7.5  2017-01-22 21:07:23   2017-01-22 21:14:19   \n",
       "3         12.96          9.5  2017-01-22 21:37:01   2017-01-22 21:46:48   \n",
       "4         11.16          8.0  2017-01-22 21:55:06   2017-01-22 22:03:13   \n",
       "\n",
       "   trip_distance  \n",
       "0           4.74  \n",
       "1           5.56  \n",
       "2           1.61  \n",
       "3           2.28  \n",
       "4           1.71  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sql = '''\n",
    "SELECT \n",
    "    total_amount, fare_amount, lpep_pickup_datetime, lpep_dropoff_datetime, trip_distance \n",
    "FROM {} WHERE total_amount is not null;\n",
    "'''.format(table_name)\n",
    "print('Querying...', data_sql)\n",
    "\n",
    "data_df = cursor.execute(data_sql).as_pandas()\n",
    "print('Status: {}, Run time: {:.2f}s, Data scanned: {:.2f}MB, Records: {:,}'.format(cursor.state, \n",
    "    cursor.execution_time_in_millis/1000.0, cursor.data_scanned_in_bytes/1024.0/1024.0, data_df.shape[0]))\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance some simple feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some date features\n",
    "data_df['lpep_pickup_datetime'] = data_df['lpep_pickup_datetime'].astype('datetime64[ns]')\n",
    "data_df['lpep_dropoff_datetime'] = data_df['lpep_dropoff_datetime'].astype('datetime64[ns]')\n",
    "data_df['duration_minutes'] = (data_df['lpep_dropoff_datetime'] - data_df['lpep_pickup_datetime']).dt.seconds/60\n",
    "data_df['hour_of_day'] = data_df['lpep_pickup_datetime'].dt.hour\n",
    "data_df['day_of_week'] = data_df['lpep_pickup_datetime'].dt.dayofweek\n",
    "data_df['week_of_year'] = data_df['lpep_pickup_datetime'].dt.weekofyear\n",
    "data_df['month_of_year'] = data_df['lpep_pickup_datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046381, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.30</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2017-01-22 21:49:27</td>\n",
       "      <td>2017-01-22 22:07:02</td>\n",
       "      <td>4.74</td>\n",
       "      <td>17.583333</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.16</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2017-01-22 21:52:32</td>\n",
       "      <td>2017-01-22 22:15:40</td>\n",
       "      <td>5.56</td>\n",
       "      <td>23.133333</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.56</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2017-01-22 21:07:23</td>\n",
       "      <td>2017-01-22 21:14:19</td>\n",
       "      <td>1.61</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.96</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2017-01-22 21:37:01</td>\n",
       "      <td>2017-01-22 21:46:48</td>\n",
       "      <td>2.28</td>\n",
       "      <td>9.783333</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-01-22 21:55:06</td>\n",
       "      <td>2017-01-22 22:03:13</td>\n",
       "      <td>1.71</td>\n",
       "      <td>8.116667</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_amount  fare_amount lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "0         20.30         16.5  2017-01-22 21:49:27   2017-01-22 22:07:02   \n",
       "1         26.16         20.5  2017-01-22 21:52:32   2017-01-22 22:15:40   \n",
       "2         10.56          7.5  2017-01-22 21:07:23   2017-01-22 21:14:19   \n",
       "3         12.96          9.5  2017-01-22 21:37:01   2017-01-22 21:46:48   \n",
       "4         11.16          8.0  2017-01-22 21:55:06   2017-01-22 22:03:13   \n",
       "\n",
       "   trip_distance  duration_minutes  hour_of_day  day_of_week  week_of_year  \\\n",
       "0           4.74         17.583333           21            6             3   \n",
       "1           5.56         23.133333           21            6             3   \n",
       "2           1.61          6.933333           21            6             3   \n",
       "3           2.28          9.783333           21            6             3   \n",
       "4           1.71          8.116667           21            6             3   \n",
       "\n",
       "   month_of_year  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude any outliers\n",
    "data_df = data_df[(data_df.total_amount > 0) & (data_df.total_amount < 200) & \n",
    "                  (data_df.duration_minutes > 0) & (data_df.duration_minutes < 120) & \n",
    "                  (data_df.trip_distance > 0) & (data_df.trip_distance < 1000)].dropna()\n",
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Build an XGBoost model to predict the total amount based on some fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket: sagemaker-us-east-1-840276314986, prefix: nyc-taxi\n"
     ]
    }
   ],
   "source": [
    "import boto3 \n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "role = sagemaker.get_execution_role()\n",
    "prefix = 'nyc-taxi'\n",
    "\n",
    "print('bucket: {}, prefix: {}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train: 837104, val: 104638, test: 104639 \n"
     ]
    }
   ],
   "source": [
    "# Trip test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_cols = ['total_amount', 'duration_minutes', 'trip_distance', 'hour_of_day']\n",
    "train_df, val_df = train_test_split(data_df[train_cols], test_size=0.20, random_state=42)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.50, random_state=42)\n",
    "\n",
    "print('split train: {}, val: {}, test: {} '.format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and save files with target as first column\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data\n",
    "\n",
    "Save train and validation as CSV with `total_amount` as first col but no headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the tpep_pickup_datetime and save\n",
    "train_df.to_csv('train.csv', index=False, header=False)\n",
    "val_df.to_csv('validation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 189 ms, sys: 58.6 ms, total: 247 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Uplaod the files to s3 \n",
    "s3_train_uri = sagemaker_session.upload_data('train.csv', bucket, prefix + '/data/training')\n",
    "s3_val_uri = sagemaker_session.upload_data('validation.csv', bucket, prefix + '/data/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that we have uploaded these files succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 09:44:20   22030287 train.csv\n",
      "2020-12-13 09:44:21    2751797 validation.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_train_uri \n",
    "!aws s3 ls $s3_val_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve(region=region, framework=\"xgboost\", version=\"latest\")\n",
    "print('container: {}'.format(container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: s3://sagemaker-us-east-1-840276314986/nyc-taxi/output\n"
     ]
    }
   ],
   "source": [
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('output: {}'.format(output_path))\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 09:44:41 Starting - Starting the training job...\n",
      "2020-12-13 09:45:05 Starting - Launching requested ML instancesProfilerReport-1607852681: InProgress\n",
      ".........\n",
      "2020-12-13 09:46:26 Starting - Preparing the instances for training...\n",
      "2020-12-13 09:47:09 Downloading - Downloading input data.........\n",
      "2020-12-13 09:48:36 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-12-13:09:48:37:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-12-13:09:48:37:INFO] File size need to be processed in the node: 23.63mb. Available memory size in the node: 8424.12mb\u001b[0m\n",
      "\u001b[34m[2020-12-13:09:48:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[09:48:37] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[09:48:38] 837104x3 matrix with 2511312 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-12-13:09:48:38:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[09:48:38] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[09:48:38] 104638x3 matrix with 313914 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[09:48:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 514 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:13.0865#011validation-rmse:13.1028\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[09:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 542 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:10.6256#011validation-rmse:10.6393\u001b[0m\n",
      "\u001b[34m[09:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 552 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:8.68932#011validation-rmse:8.70212\u001b[0m\n",
      "\u001b[34m[09:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 546 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:7.18002#011validation-rmse:7.19337\u001b[0m\n",
      "\u001b[34m[09:48:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 582 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:6.01607#011validation-rmse:6.03074\u001b[0m\n",
      "\u001b[34m[09:48:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 576 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:5.13394#011validation-rmse:5.15123\u001b[0m\n",
      "\u001b[34m[09:48:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 606 extra nodes, 4 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:4.47765#011validation-rmse:4.4989\u001b[0m\n",
      "\u001b[34m[09:48:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 606 extra nodes, 8 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:4.00148#011validation-rmse:4.02727\u001b[0m\n",
      "\u001b[34m[09:48:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 600 extra nodes, 4 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:3.66214#011validation-rmse:3.69187\u001b[0m\n",
      "\u001b[34m[09:48:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 604 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:3.42589#011validation-rmse:3.46016\u001b[0m\n",
      "\u001b[34m[09:48:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 580 extra nodes, 8 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:3.26553#011validation-rmse:3.30396\u001b[0m\n",
      "\u001b[34m[09:48:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 516 extra nodes, 14 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:3.1568#011validation-rmse:3.19945\u001b[0m\n",
      "\u001b[34m[09:48:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 430 extra nodes, 4 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:3.08528#011validation-rmse:3.13136\u001b[0m\n",
      "\u001b[34m[09:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 424 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:3.03804#011validation-rmse:3.08725\u001b[0m\n",
      "\u001b[34m[09:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 350 extra nodes, 4 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:3.006#011validation-rmse:3.05747\u001b[0m\n",
      "\u001b[34m[09:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 272 extra nodes, 6 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:2.98447#011validation-rmse:3.0377\u001b[0m\n",
      "\u001b[34m[09:48:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 258 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:2.97035#011validation-rmse:3.0254\u001b[0m\n",
      "\u001b[34m[09:48:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 270 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:2.96066#011validation-rmse:3.01725\u001b[0m\n",
      "\u001b[34m[09:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 192 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:2.95396#011validation-rmse:3.01223\u001b[0m\n",
      "\u001b[34m[09:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 156 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:2.94972#011validation-rmse:3.00862\u001b[0m\n",
      "\u001b[34m[09:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 136 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:2.94569#011validation-rmse:3.00562\u001b[0m\n",
      "\u001b[34m[09:48:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 2 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:2.94362#011validation-rmse:3.00455\u001b[0m\n",
      "\u001b[34m[09:48:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:2.94195#011validation-rmse:3.00341\u001b[0m\n",
      "\u001b[34m[09:48:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:2.94061#011validation-rmse:3.00257\u001b[0m\n",
      "\u001b[34m[09:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:2.93939#011validation-rmse:3.00259\u001b[0m\n",
      "\u001b[34m[09:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:2.93847#011validation-rmse:3.00267\u001b[0m\n",
      "\u001b[34m[09:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:2.93693#011validation-rmse:3.0006\u001b[0m\n",
      "\u001b[34m[09:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:2.93632#011validation-rmse:2.99996\u001b[0m\n",
      "\u001b[34m[09:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:2.93579#011validation-rmse:3.00029\u001b[0m\n",
      "\u001b[34m[09:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:2.93536#011validation-rmse:3.00007\u001b[0m\n",
      "\u001b[34m[09:48:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:2.93429#011validation-rmse:2.99911\u001b[0m\n",
      "\u001b[34m[09:48:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:2.934#011validation-rmse:2.9992\u001b[0m\n",
      "\u001b[34m[09:48:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:2.9337#011validation-rmse:2.99896\u001b[0m\n",
      "\u001b[34m[09:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:2.93321#011validation-rmse:2.99887\u001b[0m\n",
      "\u001b[34m[09:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:2.93279#011validation-rmse:2.99867\u001b[0m\n",
      "\u001b[34m[09:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:2.93253#011validation-rmse:2.99952\u001b[0m\n",
      "\u001b[34m[09:48:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:2.9322#011validation-rmse:2.99998\u001b[0m\n",
      "\u001b[34m[09:48:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:2.93176#011validation-rmse:2.99946\u001b[0m\n",
      "\u001b[34m[09:48:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:2.93155#011validation-rmse:2.99953\u001b[0m\n",
      "\u001b[34m[09:48:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:2.9312#011validation-rmse:2.99939\u001b[0m\n",
      "\u001b[34m[09:48:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:2.93065#011validation-rmse:2.99924\u001b[0m\n",
      "\u001b[34m[09:48:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:2.93049#011validation-rmse:2.99923\u001b[0m\n",
      "\u001b[34m[09:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:2.93003#011validation-rmse:2.99973\u001b[0m\n",
      "\u001b[34m[09:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:2.92977#011validation-rmse:2.99959\u001b[0m\n",
      "\u001b[34m[09:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:2.92946#011validation-rmse:2.99938\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:2.93279#011validation-rmse:2.99867\n",
      "\u001b[0m\n",
      "\n",
      "2020-12-13 09:49:09 Uploading - Uploading generated training model\n",
      "2020-12-13 09:49:09 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n"
     ]
    }
   ],
   "source": [
    "xgb.set_hyperparameters(max_depth=9,\n",
    "                        eta=0.2, \n",
    "                        gamma=4,\n",
    "                        min_child_weight=300,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=10000)\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=s3_train_uri, content_type=\"csv\")\n",
    "s3_input_val = sagemaker.inputs.TrainingInput(s3_data=s3_val_uri, content_type=\"csv\")\n",
    "\n",
    "xgb.fit({'train': s3_input_train,  'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name='xgb-athena-integration-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalulate Model\n",
    "\n",
    "Get predicitons for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "xgb_predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:04<00:00, 47.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 166 ms, total: 1.59 s\n",
      "Wall time: 4.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in tqdm(split_array):\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "# Get predictions and store in df\n",
    "predictions = predict(val_df[train_cols[1:]].values)\n",
    "predictions = pd.DataFrame({'total_amount_predictions': predictions })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>total_amount_predictions</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45359</th>\n",
       "      <td>20.76</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>2.289000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>5.38</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20</td>\n",
       "      <td>5.379971</td>\n",
       "      <td>2.944946e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42849</th>\n",
       "      <td>14.08</td>\n",
       "      <td>14.716667</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13</td>\n",
       "      <td>14.080075</td>\n",
       "      <td>7.526400e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>8.80</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0.65</td>\n",
       "      <td>19</td>\n",
       "      <td>8.799897</td>\n",
       "      <td>1.028061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77665</th>\n",
       "      <td>14.30</td>\n",
       "      <td>16.550000</td>\n",
       "      <td>2.40</td>\n",
       "      <td>7</td>\n",
       "      <td>14.300106</td>\n",
       "      <td>1.060486e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>16.30</td>\n",
       "      <td>15.483333</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1</td>\n",
       "      <td>16.299704</td>\n",
       "      <td>2.964020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100119</th>\n",
       "      <td>36.36</td>\n",
       "      <td>15.933333</td>\n",
       "      <td>10.88</td>\n",
       "      <td>10</td>\n",
       "      <td>36.360481</td>\n",
       "      <td>4.812622e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86318</th>\n",
       "      <td>59.16</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>17.39</td>\n",
       "      <td>20</td>\n",
       "      <td>59.159405</td>\n",
       "      <td>5.952454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64403</th>\n",
       "      <td>19.80</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>3.63</td>\n",
       "      <td>18</td>\n",
       "      <td>19.800652</td>\n",
       "      <td>6.515503e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40555</th>\n",
       "      <td>14.80</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9</td>\n",
       "      <td>14.800687</td>\n",
       "      <td>6.868362e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_amount  duration_minutes  trip_distance  hour_of_day  \\\n",
       "45359          20.76         18.050000           5.00            8   \n",
       "9445            5.38          1.150000           0.22           20   \n",
       "42849          14.08         14.716667           2.68           13   \n",
       "25607           8.80          7.833333           0.65           19   \n",
       "77665          14.30         16.550000           2.40            7   \n",
       "19321          16.30         15.483333           3.31            1   \n",
       "100119         36.36         15.933333          10.88           10   \n",
       "86318          59.16         32.100000          17.39           20   \n",
       "64403          19.80         22.800000           3.63           18   \n",
       "40555          14.80         12.600000           3.32            9   \n",
       "\n",
       "        total_amount_predictions         error  \n",
       "45359                  20.760000  2.289000e-07  \n",
       "9445                    5.379971  2.944946e-05  \n",
       "42849                  14.080075  7.526400e-05  \n",
       "25607                   8.799897  1.028061e-04  \n",
       "77665                  14.300106  1.060486e-04  \n",
       "19321                  16.299704  2.964020e-04  \n",
       "100119                 36.360481  4.812622e-04  \n",
       "86318                  59.159405  5.952454e-04  \n",
       "64403                  19.800652  6.515503e-04  \n",
       "40555                  14.800687  6.868362e-04  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the abs error between predictions\n",
    "pred_df = val_df.join(predictions)\n",
    "pred_df['error'] = abs(pred_df['total_amount']-pred_df['total_amount_predictions'])\n",
    "pred_df.sort_values('error', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Athena UDF \n",
    "\n",
    "Create a [User Defined Function](https://aws.amazon.com/blogs/big-data/prepare-data-for-model-training-and-invoke-machine-learning-models-with-amazon-athena/) for the deployed endpoint so you can query directly in Athena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint: xgb-athena-integration-endpoint\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = xgb_predictor.endpoint_name\n",
    "print('endpoint: {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOTE`: Athena ML is [in preview](https://aws.amazon.com/athena/faqs/#Preview_features).   To enable this Preview feature you need to create an Athena workgroup named `AmazonAthenaPreviewFunctionality` and run any queries attempting to federate to this connector, use a UDF, or SageMaker inference from that workgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "workgroup_name = 'AmazonAthenaPreviewFunctionality'\n",
    "\n",
    "!aws athena create-work-group --name $workgroup_name --region $region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using presto [datetime](https://prestodb.io/docs/0.172/functions/datetime.html) functions with inline query, rank by absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying... \n",
      "USING FUNCTION predict_total(\n",
      "  duration_minutes DOUBLE, \n",
      "  trip_distance DOUBLE, \n",
      "  hour_of_day DOUBLE) returns DOUBLE type SAGEMAKER_INVOKE_ENDPOINT\n",
      "WITH (sagemaker_endpoint='xgb-athena-integration-endpoint')\n",
      "\n",
      "SELECT \n",
      "    *, ABS(predicted_total_amount-total_amount) as error\n",
      "FROM ( \n",
      "    SELECT\n",
      "        *,\n",
      "        predict_total(duration_minutes, trip_distance, hour_of_day) as predicted_total_amount\n",
      "    FROM \n",
      "    (\n",
      "        SELECT \n",
      "            total_amount,\n",
      "            CAST(date_diff('minute', \n",
      "                CAST(lpep_pickup_datetime as timestamp), \n",
      "                CAST(lpep_dropoff_datetime as timestamp)) as DOUBLE) as duration_minutes,\n",
      "            CAST(trip_distance as DOUBLE) as trip_distance,\n",
      "            CAST(hour(CAST(lpep_pickup_datetime as timestamp)) as double) as hour_of_day\n",
      "        FROM nyc_taxi.taxi_csv\n",
      "        WHERE DAY(CAST(lpep_pickup_datetime as timestamp)) = 1 -- Filter by day\n",
      "    )\n",
      ")\n",
      "ORDER BY error DESC\n",
      "LIMIT 10;\n",
      "\n",
      "Status: SUCCEEDED, Run time: 13.28s, Data scanned: 91.34MB, Records: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>predicted_total_amount</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.547598</td>\n",
       "      <td>222.452402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276.64</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>96.674095</td>\n",
       "      <td>179.965905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.677799</td>\n",
       "      <td>136.122201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203.16</td>\n",
       "      <td>43.0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>11.0</td>\n",
       "      <td>96.393600</td>\n",
       "      <td>106.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.00</td>\n",
       "      <td>193.0</td>\n",
       "      <td>52.96</td>\n",
       "      <td>22.0</td>\n",
       "      <td>104.396317</td>\n",
       "      <td>97.396317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>141.30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.14</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47.895618</td>\n",
       "      <td>93.404382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-68.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.884491</td>\n",
       "      <td>91.194491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>92.397316</td>\n",
       "      <td>87.597316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>26.49</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.674095</td>\n",
       "      <td>86.674095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>104.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.547598</td>\n",
       "      <td>86.452402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_amount  duration_minutes  trip_distance  hour_of_day  \\\n",
       "0        240.00               0.0           0.00          4.0   \n",
       "1        276.64              49.0          48.20          8.0   \n",
       "2        140.80               1.0           0.20         10.0   \n",
       "3        203.16              43.0          38.59         11.0   \n",
       "4          7.00             193.0          52.96         22.0   \n",
       "5        141.30              46.0          12.14         16.0   \n",
       "6        -68.31               0.0           0.01         17.0   \n",
       "7          4.80               5.0          26.40         14.0   \n",
       "8         10.00              52.0          26.49          7.0   \n",
       "9        104.00               0.0           0.00          6.0   \n",
       "\n",
       "   predicted_total_amount       error  \n",
       "0               17.547598  222.452402  \n",
       "1               96.674095  179.965905  \n",
       "2                4.677799  136.122201  \n",
       "3               96.393600  106.766400  \n",
       "4              104.396317   97.396317  \n",
       "5               47.895618   93.404382  \n",
       "6               22.884491   91.194491  \n",
       "7               92.397316   87.597316  \n",
       "8               96.674095   86.674095  \n",
       "9               17.547598   86.452402  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sql  = '''\n",
    "USING FUNCTION predict_total(\n",
    "  duration_minutes DOUBLE, \n",
    "  trip_distance DOUBLE, \n",
    "  hour_of_day DOUBLE) returns DOUBLE type SAGEMAKER_INVOKE_ENDPOINT\n",
    "WITH (sagemaker_endpoint='{}')\n",
    "\n",
    "SELECT \n",
    "    *, ABS(predicted_total_amount-total_amount) as error\n",
    "FROM ( \n",
    "    SELECT\n",
    "        *,\n",
    "        predict_total(duration_minutes, trip_distance, hour_of_day) as predicted_total_amount\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            total_amount,\n",
    "            CAST(date_diff('minute', \n",
    "                CAST(lpep_pickup_datetime as timestamp), \n",
    "                CAST(lpep_dropoff_datetime as timestamp)) as DOUBLE) as duration_minutes,\n",
    "            CAST(trip_distance as DOUBLE) as trip_distance,\n",
    "            CAST(hour(CAST(lpep_pickup_datetime as timestamp)) as double) as hour_of_day\n",
    "        FROM {}\n",
    "        WHERE DAY(CAST(lpep_pickup_datetime as timestamp)) = {} -- Filter by day\n",
    "    )\n",
    ")\n",
    "ORDER BY error DESC\n",
    "LIMIT {};\n",
    "'''.format(endpoint_name, table_name, 1, 10)\n",
    "print('Querying...', query_sql)\n",
    "\n",
    "query_df = cursor.execute(query_sql, work_group=workgroup_name).as_pandas()\n",
    "print('Status: {}, Run time: {:.2f}s, Data scanned: {:.2f}MB, Records: {:,}'.format(cursor.state, \n",
    "    cursor.execution_time_in_millis/1000.0, cursor.data_scanned_in_bytes/1024.0/1024.0, query_df.shape[0]))\n",
    "\n",
    "query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
