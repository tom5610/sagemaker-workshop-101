{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Keras MNIST Classifier - Local Example\n",
    "\n",
    "This notebook trains and exports a Keras CNN-based classifier for (a subset of) the MNIST DIGITS dataset, performing all storage and computation here on the notebook instance where you run it.\n",
    "\n",
    "To give a better idea of how you might **apply the example to real-world problems**, we **convert the dataset** from its standard pixel array format to a \"folders of JPEGs\" setting more typical in image classification projects just starting out. For MNIST (where the images are all tiny and uniform size), this is a much less efficient storage method - so we sample a subset of the data to keep things performant.\n",
    "\n",
    "Can you figure out how to re-create this workflow using SageMaker more effectively?\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Explore the Data](#Explore-the-Data)\n",
    "1. [Convert the Data Format](#Convert-the-Data-Format)\n",
    "1. [Load the Data From File](#Load-the-Data-From-File)\n",
    "1. [Pre-Process the Data for our CNN](#Pre-Process-the-Data-for-our-CNN)\n",
    "1. [Build a Model](#Build-a-Model)\n",
    "1. [Fit the Model](#Fit-the-Model)\n",
    "1. [Save the Trained Model](#Save-the-Trained-Model)\n",
    "1. [Explore Results](#Explore-Results)\n",
    "\n",
    "See the accompanying **Instructions** notebook for more guidance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# matplotlib may not be installed by default on some kernels (e.g. SMStudio TF CPU Optimized)\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using TensorFlow version {tf.__version__}\")\n",
    "print(f\"Keras version {tf.keras.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "Let's use the Keras built-in to load the MNIST data, but explore exactly what format that gives us:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# To keep things snappy for the exercise (you'll see why later), we will scale back the data:\n",
    "x_train_raw = x_train_raw[0:len(x_train_raw) // 2]\n",
    "y_train_raw = y_train_raw[0:len(y_train_raw) // 2]\n",
    "x_test_raw = x_test_raw[0:len(x_test_raw) // 2]\n",
    "y_test_raw = y_test_raw[0:len(y_test_raw) // 2]\n",
    "\n",
    "print(f\"x_train.shape {x_train_raw.shape}; dtype {x_train_raw.dtype}\")\n",
    "print(f\"y_train.shape {y_train_raw.shape}; dtype {y_train_raw.dtype}\")\n",
    "print(f\"x_test.shape {x_test_raw.shape}; dtype {x_test_raw.dtype}\")\n",
    "print(f\"y_test.shape {y_test_raw.shape}; dtype {y_test_raw.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train_raw.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train_raw)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data is pretty evenly distributed between labels 0-9, and our images are encoded by fixed-size 28x28 uint8 matrices from 0 to 255. Here we'll just plot a few examples to get a feel for them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    fig = plt.subplot(1, 5, i + 1)\n",
    "    ax = plt.imshow(x_train_raw[i], cmap=\"gray\")\n",
    "    fig.set_title(f\"Number {y_train_raw[i]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Data Format\n",
    "\n",
    "Now let's create a folder for each class 0-9, and save all the images in their associated folder... It's a bit easier to relate to than the pre-prepared numpy arrays!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!rm -rf data/train\n",
    "!rm -rf data/test\n",
    "\n",
    "# This can take a while due to the number of images\n",
    "def save_to_disk(x, y, base_folder):\n",
    "    \"\"\"Save an image classification dataset to disk as JPEGs in label-named folders\"\"\"\n",
    "    for ix in range(len(y)):\n",
    "        label_str = \"digit-%d\" % y[ix]\n",
    "        os.makedirs(os.path.join(base_folder, label_str), exist_ok=True)\n",
    "        tf.keras.preprocessing.image.save_img(\n",
    "            os.path.join(base_folder, label_str, \"%s-%06d.jpg\" % (label_str, ix)),\n",
    "            # This function expects a channels dimension, which we'll add in first:\n",
    "            np.expand_dims(x[ix], 0),\n",
    "            data_format=\"channels_first\"\n",
    "        )\n",
    "\n",
    "print(\"Saving training data...\")\n",
    "os.makedirs(\"data/train\", exist_ok=True)\n",
    "save_to_disk(x_train_raw, y_train_raw, \"data/train\")\n",
    "print(\"Saving test data...\")\n",
    "os.makedirs(\"data/test\", exist_ok=True)\n",
    "save_to_disk(x_test_raw, y_test_raw, \"data/test\")\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data From File\n",
    "\n",
    "Now our images are stored in the `data/` folder, let's ignore the Keras built-in method and read our training and test sets in from these files.\n",
    "\n",
    "```\n",
    "    ./data\n",
    "    |----------------.\n",
    "    `-- test          `-- train\n",
    "        |-- digit-0       |-- digit-0\n",
    "        |                     `-- digit-0-000001.jpg, etc.\n",
    "        |-- digit-1       |-- digit-1\n",
    "        |-- digit-2       |-- digit-2\n",
    "        |-- digit-3       |-- digit-3\n",
    "        |-- digit-4       |-- digit-4\n",
    "        |-- digit-5       |-- digit-5\n",
    "        |-- digit-6       |-- digit-6\n",
    "        |-- digit-7       |-- digit-7\n",
    "        |-- digit-8       |-- digit-8\n",
    "        `-- digit-9       `-- digit-9\n",
    "```\n",
    "\n",
    "(For both training and test) We'll loop through each folder taking the target label (`0`-`9`) from the folder name and loading loading each JPEG into an image matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May as well clear out the old memory, in case you're running a small instance:\n",
    "x_train_raw = None\n",
    "y_train_raw = None\n",
    "x_test_raw = None\n",
    "y_test_raw = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "labels = sorted(os.listdir(\"data/train\"))\n",
    "n_labels = len(labels)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "print(\"Loading label \", end=\"\")\n",
    "for ix_label in range(n_labels):\n",
    "    label_str = labels[ix_label]\n",
    "    print(f\"{label_str}...\", end=\"\")\n",
    "    trainfiles = filter(\n",
    "        lambda s: s.endswith(\".jpg\"),\n",
    "        os.listdir(os.path.join(\"data/train\", label_str))\n",
    "    )\n",
    "    for filename in trainfiles:\n",
    "        # Can't just use tf.keras.preprocessing.image.load_img(), because it doesn't close its file\n",
    "        # handles! So get \"Too many open files\" error... Grr\n",
    "        with open(os.path.join(\"data/train\", label_str, filename), \"rb\") as imgfile:\n",
    "            x_train.append(\n",
    "                # Squeeze (drop) that extra channel dimension, to be consistent with prev format:\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_train.append(ix_label)\n",
    "    # Repeat for test data:\n",
    "    testfiles = filter(\n",
    "        lambda s: s.endswith(\".jpg\"),\n",
    "        os.listdir(os.path.join(\"data/test\", label_str))\n",
    "    )\n",
    "    for filename in testfiles:\n",
    "        with open(os.path.join(\"data/test\", label_str, filename), \"rb\") as imgfile:\n",
    "            x_test.append(\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_test.append(ix_label)\n",
    "print()\n",
    "\n",
    "print(\"Shuffling trainset...\")\n",
    "train_shuffled = [(x_train[ix], y_train[ix]) for ix in range(len(y_train))]\n",
    "np.random.shuffle(train_shuffled)\n",
    "\n",
    "x_train = np.array([datum[0] for datum in train_shuffled])\n",
    "y_train = np.array([datum[1] for datum in train_shuffled])\n",
    "train_shuffled = None\n",
    "\n",
    "print(\"Shuffling testset...\")\n",
    "test_shuffled = [(x_test[ix], y_test[ix]) for ix in range(len(y_test))]\n",
    "np.random.shuffle(test_shuffled)\n",
    "\n",
    "x_test = np.array([datum[0] for datum in test_shuffled])\n",
    "y_test = np.array([datum[1] for datum in test_shuffled])\n",
    "test_shuffled = None\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we go ahead**, let's just quickly validate that the data is the same distribution as the original... Just shuffled in order:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data()\n",
    "print(f\"x_train.shape {x_train_raw.shape}; dtype {x_train_raw.dtype}\")\n",
    "print(f\"y_train.shape {y_train_raw.shape}; dtype {y_train_raw.dtype}\")\n",
    "print(f\"x_test.shape {x_test_raw.shape}; dtype {x_test_raw.dtype}\")\n",
    "print(f\"y_test.shape {y_test_raw.shape}; dtype {y_test_raw.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train_raw.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train_raw)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    fig = plt.subplot(1, 5, i + 1)\n",
    "    ax = plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    fig.set_title(f\"Number {y_train[i]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the distributions haven't shifted, and the advertised labels still visually match the images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process the Data for our CNN\n",
    "\n",
    "We've recovered the dataset from our JPEG files back to the MNIST original format, and verified nothing's majorly broken...\n",
    "\n",
    "Next, we'll tweak this format for our neural network:\n",
    "\n",
    "- Normalizing pixel values to improve the numerical conditioning\n",
    "- One-hot encoding our labels to suit a softmax classifier output of probabilities for each digit\n",
    "- Adding both a batch dimension (for processing multiple samples in parallel) and a channel dimension (e.g. as if this were a 3-channel RGB image, except single-channel for grayscale) - as well as the X and Y axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're actually feeding the images in to nets this time, we should actually pay attention\n",
    "# to which way around Keras wants the channel dimension:\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    x_train = np.expand_dims(x_train, 1)\n",
    "    x_test = np.expand_dims(x_train, 1)\n",
    "else:\n",
    "    x_train = np.expand_dims(x_train, len(x_train.shape))\n",
    "    x_test = np.expand_dims(x_test, len(x_test.shape))\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_labels)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_labels)\n",
    "\n",
    "print(\"n_labels:\", n_labels)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "\n",
    "At its core, the model is a 2D convolutional network with a softmax output layer that'll yield a confidence score for every possible label (e.g. 10 options for digit = 0 to 9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_labels, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "\n",
    "Keras makes fitting and evaluating the model straightforward enough: We don't have any fancy hooks, and are happy with the default logging:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1, # Hint: You might prefer =2 for running in SageMaker!\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss={score[0]}\")\n",
    "print(f\"Test accuracy={score[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "Keras has a built-in `model.save()` command, which in TensorFlow v2 can directly produce TensorFlow Serving-compatible outputs!\n",
    "\n",
    "...However, this notebook runs TensorFlow v1. To save you the frustration of figuring it out (there's a nice blog post on the subject [here](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/)), we'll give you a hint by saving the model here in TensorFlow Serving-ready format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The export folder needs to be empty, or non-existent\n",
    "!rm -rf data/model/model/1\n",
    "\n",
    "sess = K.get_session()\n",
    "tf.saved_model.simple_save(\n",
    "    sess,\n",
    "    os.path.join(\"data/model\", \"model/1\"),\n",
    "    inputs={ \"inputs\": model.input },\n",
    "    outputs={ t.name: t for t in model.outputs },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    "\n",
    "Let's take a sample image from the test set, predict the label and plot it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image:\n",
    "label = \"2\"\n",
    "filename = os.listdir(f\"data/test/digit-{label}\")[0]\n",
    "\n",
    "# Load the image:\n",
    "img = tf.keras.preprocessing.image.img_to_array(\n",
    "    Image.open(f\"data/test/digit-{label}/{filename}\")\n",
    ")\n",
    "\n",
    "# Expand out the \"batch\" dimension, and send to the model:\n",
    "result = model.predict(np.expand_dims(img, 0))\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted Number {np.argmax(result[0])}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
